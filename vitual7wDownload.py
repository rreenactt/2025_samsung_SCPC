# download_dataset.py
from datasets import load_dataset
import os
import pandas as pd
import re
from tqdm import tqdm

def parse_entry(entry):
    """
    ë°ì´í„°ì…‹ì˜ í•œ í–‰(entry)ì„ ë°›ì•„ ì§ˆë¬¸, ì„ íƒì§€, ì •ë‹µì„ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        text_data_list = entry.get('texts')
        if not text_data_list:
            return None

        first_turn = text_data_list[0]
        user_text = first_turn.get('user')
        assistant_text = first_turn.get('assistant')

        if not user_text or not assistant_text:
            return None

        # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ê° ë¶€ë¶„ì„ ì¶”ì¶œ
        question_match = re.search(r"Question:(.*?)\nChoices:", user_text, re.DOTALL)
        option_a_match = re.search(r"\nA\.\s(.*?)\nB\.", user_text, re.DOTALL)
        option_b_match = re.search(r"\nB\.\s(.*?)\nC\.", user_text, re.DOTALL)
        option_c_match = re.search(r"\nC\.\s(.*?)\nD\.", user_text, re.DOTALL)
        option_d_match = re.search(r"\nD\.\s(.*?)\nAnswer with the letter\.", user_text, re.DOTALL)
        answer_letter_match = re.search(r"Answer:\s*([A-D])", assistant_text)

        if not all([question_match, option_a_match, option_b_match, option_c_match, option_d_match, answer_letter_match]):
            return None

        question = question_match.group(1).strip()
        options = {
            'A': option_a_match.group(1).strip(),
            'B': option_b_match.group(1).strip(),
            'C': option_c_match.group(1).strip(),
            'D': option_d_match.group(1).strip(),
        }
        answer_letter = answer_letter_match.group(1).strip().upper()
        
        answer_text = options.get(answer_letter)

        if not answer_text:
            return None

        return {
            "question": question,
            "answer": answer_text,
            "image": entry['images'][0],
            "id": entry.get('image_id')
        }
    except (KeyError, IndexError, AttributeError):
        return None


def download_and_prepare_dataset():
    """
    Hugging Face Hubì˜ the_cauldron ë°ì´í„°ì…‹ì—ì„œ visual7w ì„œë¸Œì…‹ ì „ì²´ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ ,
    í•™ìŠµì— í•„ìš”í•œ í˜•ì‹ì˜ CSV íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    """
    output_folder = "open"
    os.makedirs(output_folder, exist_ok=True)
    # ğŸ“Œ í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ì´ë¦„(_test)ì„ ì›ë˜ëŒ€ë¡œ ë³€ê²½
    output_path = os.path.join(output_folder, "vitual7w.csv")

    print("HuggingFaceM4/the_cauldronì—ì„œ 'visual7w' ì„œë¸Œì…‹ ì „ì²´ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
    
    try:
        dataset = load_dataset("HuggingFaceM4/the_cauldron", name="visual7w", split="train")
    except Exception as e:
        print(f"ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    processed_data = []
    print("ë°ì´í„°ë¥¼ í•™ìŠµ í˜•ì‹ì— ë§ê²Œ íŒŒì‹±í•˜ê³  ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤ (ì „ì²´ ë°ì´í„°)...")
    
    # ğŸ“Œ 5ê°œ ì œí•œ ë¡œì§ì„ ì œê±°í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ë„ë¡ í•¨
    for index, entry in enumerate(tqdm(dataset, desc="Processing")):
        parsed = parse_entry(entry)
        
        if parsed:
            image_id = parsed.get('id') or f'v7w_{index}'
            image_folder = os.path.join(output_folder, 'v7w_images')
            os.makedirs(image_folder, exist_ok=True)
            
            image_path = os.path.join(image_folder, f"{image_id}.png")
            parsed['image'].save(image_path)
            
            relative_img_path = os.path.join('v7w_images', f"{image_id}.png").replace('\\', '/')

            processed_data.append({
                'ID': image_id,
                'img_path': relative_img_path,
                'Question': parsed['question'],
                'answer': parsed['answer']
            })

    final_df = pd.DataFrame(processed_data)
    
    final_df.to_csv(output_path, index=False, encoding='utf-8-sig')

    print(f"\në‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì™„ë£Œ! ì „ì²´ íŒŒì¼ì´ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ì´ë¯¸ì§€ë“¤ì€ 'open/v7w_images' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\nCSV ìƒ˜í”Œ:")
    print(final_df.head())

if __name__ == "__main__":
    download_and_prepare_dataset()